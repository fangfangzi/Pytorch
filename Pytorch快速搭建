import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
import torch.utils.data as DATA
import torch.autograd.variable as Variable




n_data = torch.ones(100, 2)
x0 = torch.normal(2*n_data, 1)      # class0 x data (tensor), shape=(100, 2)
y0 = torch.zeros(100)               # class0 y data (tensor), shape=(100, 1)
x1 = torch.normal(-2*n_data, 1)     # class1 x data (tensor), shape=(100, 2)
y1 = torch.ones(100)                # class1 y data (tensor), shape=(100, 1)
x = torch.cat((x0, x1), 0).type(torch.FloatTensor)  # shape (200, 2) FloatTensor = 32-bit floating
y = torch.cat((y0, y1), ).type(torch.LongTensor)    # shape (200,) LongTensor = 64-bit integer

torch_dataset = DATA.TensorDataset(x,y)
loader = DATA.DataLoader(dataset=torch_dataset,
                         batch_size=60,
                         shuffle=True,
                         num_workers=4,
                        )

net2 = torch.nn.Sequential(
    torch.nn.Linear(2,10),
    torch.nn.ReLU(),
    torch.nn.Linear(10,2),
)

optimizer = torch.optim.RMSprop(net2.parameters(),lr=0.05,alpha=0.9)
loss_fuc = torch.nn.CrossEntropyLoss()

if __name__ == '__main__':
    for epoch in range(3):
        for step,(batch_x,batch_y) in enumerate(loader):
            out = net2(batch_x)
            loss = loss_fuc(out,batch_y)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        print(epoch,'Finshed')
    torch.save(net2,'net.plk')
